{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datast 7 : iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importinng the PlumberOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from Plumber import PlumberOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data and performing feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (150, 4)\n",
      "Unique class labels: [0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iris Dataset - Data Loading and Preprocessing\n",
    "from sklearn.datasets import load_iris\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name=\"target\")\n",
    "\n",
    "# Preview\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Unique class labels:\", y.unique())\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (120, 4)\n",
      "Test set shape: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance and efficiency of the PlumberOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single model takes  0.055056095123291016 seconds to run\n",
      "Suggested number of trails is 150 \n",
      "Best Parameters: {'n_estimators': 250, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 15, 'max_features': 'log2'}\n",
      "Best Score: 0.975\n",
      "A single model takes  0.0342099666595459 seconds to run\n",
      "Suggested number of trails is 150 \n",
      "Best Parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'sqrt'}\n",
      "Best Score: 0.9666666666666667\n",
      "A single model takes  0.03404402732849121 seconds to run\n",
      "Suggested number of trails is 150 \n",
      "Best Parameters: {'n_estimators': 50, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 15, 'max_features': 'sqrt'}\n",
      "Best Score: 0.975\n",
      "A single model takes  0.03437471389770508 seconds to run\n",
      "Suggested number of trails is 150 \n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 15, 'max_features': 'sqrt'}\n",
      "Best Score: 0.975\n",
      "A single model takes  0.03422379493713379 seconds to run\n",
      "Suggested number of trails is 150 \n",
      "Best Parameters: {'n_estimators': 300, 'max_depth': 25, 'min_samples_split': 8, 'min_samples_leaf': 15, 'max_features': 'log2'}\n",
      "Best Score: 0.975\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*************\n",
      "Execution Time: mean=23.49 seconds, std=7.843619406365724 seconds, max=32.66302800178528 seconds, min=12.493848085403442 seconds\n",
      "CPU Usage: mean=5.74%, std=1.84%, max=9.30%, min=4.30%\n",
      "Memory Usage: mean=-1.95 MB, std=8.11 MB, max=2.98 MB, min=-18.14 MB\n",
      "Validation Score: mean=0.9400000000000001 , std=0.013333333333333332 , max=0.9666666666666667 , min=0.9333333333333333 \n"
     ]
    }
   ],
   "source": [
    "# Arrays to store execution times, memory usage, CPU usage, and evaluatin scores\n",
    "plumber_time = np.zeros(5,'float')\n",
    "plumber_mem = np.zeros(5,'float')\n",
    "plumber_cpu =  np.zeros(5,'float')\n",
    "plumber_score = np.zeros(5,'float')\n",
    "for i in range(5):\n",
    "    opt = PlumberOptimizer(X_train, y_train)\n",
    "\n",
    "    # Monitor the current process, record the start time, initial CPU usage, and memory usage in MB\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_time = time.time()\n",
    "    start_cpu = process.cpu_percent(interval=None)\n",
    "    start_mem = process.memory_info().rss / (1024 * 1024) \n",
    "\n",
    "\n",
    "    best = opt.optimize()\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_cpu = process.cpu_percent(interval=None)\n",
    "    end_mem = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "    # Calculating execution time, memory usage, and CPU usage\n",
    "    plumber_time[i] = end_time - start_time\n",
    "    plumber_mem[i] = end_mem - start_mem\n",
    "    plumber_cpu[i] = end_cpu - start_cpu\n",
    "\n",
    "    # Training and evaluating the model using the best parameters\n",
    "    rf = RandomForestClassifier(**best , random_state=42 )\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "    plumber_score[i] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# summary for the Plumber Optimizer\n",
    "print(\"\\n\" *3)\n",
    "print(\"*************\")\n",
    "print(f\"Execution Time: mean={np.mean(plumber_time):.2f} seconds, std={np.std(plumber_time)} seconds, max={np.max(plumber_time)} seconds, min={np.min(plumber_time)} seconds\")\n",
    "print(f\"CPU Usage: mean={np.mean(plumber_cpu):.2f}%, std={np.std(plumber_cpu):.2f}%, max={np.max(plumber_cpu):.2f}%, min={np.min(plumber_cpu):.2f}%\")\n",
    "print(f\"Memory Usage: mean={np.mean(plumber_mem):.2f} MB, std={np.std(plumber_mem):.2f} MB, max={np.max(plumber_mem):.2f} MB, min={np.min(plumber_mem):.2f} MB\")\n",
    "print(f\"Validation Score: mean={np.mean(plumber_score)} , std={np.std(plumber_score)} , max={np.max(plumber_score)} , min={np.min(plumber_score)} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance and efficiency of the GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: 100.31 seconds\n",
      "CPU Usage: 4.10%\n",
      "Memory Usage: 4.80 MB\n",
      "Validation Accuracy: 0.9666666666666667\n",
      "{'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 12, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# Defining GridSearch parameters\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],  \n",
    "    'max_features': ['sqrt', 'log2'],  \n",
    "    'max_depth': [10, 20, 30, 40, 50],  \n",
    "    'min_samples_split': [2, 5, 10, 12, 16, 20], \n",
    "    'min_samples_leaf': [2, 5, 6, 8,12,16, 20]  \n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Monitor the current process, record the start time, initial CPU usage, and memory usage in MB\n",
    "process = psutil.Process(os.getpid())\n",
    "start_time = time.time()\n",
    "start_cpu = process.cpu_percent(interval=None)\n",
    "start_mem = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "end_cpu = process.cpu_percent(interval=None)\n",
    "end_mem = process.memory_info().rss / (1024 * 1024) \n",
    "\n",
    "# Print metrics for GridSearch\n",
    "print(f\"Execution Time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"CPU Usage: {end_cpu - start_cpu:.2f}%\")\n",
    "print(f\"Memory Usage: {end_mem - start_mem:.2f} MB\")\n",
    "\n",
    "\n",
    "# Training the model with the best parameters and evaluate\n",
    "rf = RandomForestClassifier(** grid_search.best_params_, random_state=42 )\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance and efficiency of the RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time: mean=10.80 seconds, std=0.2820004170803458 seconds, max=11.34908676147461 seconds, min=10.532469034194946 seconds\n",
      "CPU Usage: mean=5.76%, std=0.36%, max=6.10%, min=5.20%\n",
      "Memory Usage: mean=0.20 MB, std=0.24 MB, max=0.53 MB, min=0.00 MB\n",
      "Validation Score: mean=0.9333333333333333 , std=0.0 , max=0.9333333333333333 , min=0.9333333333333333 \n"
     ]
    }
   ],
   "source": [
    "# Defining the parameter for RandomizedSearch\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 500),\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': np.arange(10, 31),\n",
    "    'min_samples_split': np.arange(2, 50),\n",
    "    'min_samples_leaf': np.arange(1, 50)\n",
    "}\n",
    "# Arrays to store execution times, memory usage, CPU usage, and evaluation scores\n",
    "rand_time = np.zeros(5,'float')\n",
    "rand_mem = np.zeros(5,'float')\n",
    "rand_cpu =  np.zeros(5,'float')\n",
    "rand_score = np.zeros(5,'float')\n",
    "for i in range(5):\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                    n_iter=250, cv=3, n_jobs=-1)\n",
    "    \n",
    "    # Monitor the current process, record the start time, initial CPU usage, and memory usage in MB\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_time = time.time()\n",
    "    start_cpu = process.cpu_percent(interval=None)\n",
    "    start_mem = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_cpu = process.cpu_percent(interval=None)\n",
    "    end_mem = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "    # Calculating execution time, memory usage, and CPU usage\n",
    "    rand_time[i] = end_time - start_time\n",
    "    rand_mem[i] = end_mem - start_mem\n",
    "    rand_cpu[i] = end_cpu - start_cpu\n",
    "\n",
    "    # Training the model with the best parameters and evaluate\n",
    "    rf = RandomForestClassifier(** random_search.best_params_ , random_state=42 )\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "    rand_score[i] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "#RandomizedSearchCV results\n",
    "print(f\"Execution Time: mean={np.mean(rand_time):.2f} seconds, std={np.std(rand_time)} seconds, max={np.max(rand_time)} seconds, min={np.min(rand_time)} seconds\")\n",
    "print(f\"CPU Usage: mean={np.mean(rand_cpu):.2f}%, std={np.std(rand_cpu):.2f}%, max={np.max(rand_cpu):.2f}%, min={np.min(rand_cpu):.2f}%\")\n",
    "print(f\"Memory Usage: mean={np.mean(rand_mem):.2f} MB, std={np.std(rand_mem):.2f} MB, max={np.max(rand_mem):.2f} MB, min={np.min(rand_mem):.2f} MB\")\n",
    "print(f\"Validation Score: mean={np.mean(rand_score)} , std={np.std(rand_score)} , max={np.max(rand_score)} , min={np.min(rand_score)} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the performance and efficiency of the BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Execution Time: mean=101.13 seconds, std=2.7627920083848605 seconds, max=104.69766402244568 seconds, min=97.34219574928284 seconds\n",
      "CPU Usage: mean=1035.62%, std=2.82%, max=1039.30%, min=1031.50%\n",
      "Memory Usage: mean=74.99 MB, std=133.88 MB, max=342.69 MB, min=4.89 MB\n",
      "Validation Score: mean=0.9333333333333333 , std=0.0 , max=0.9333333333333333 , min=0.9333333333333333 \n"
     ]
    }
   ],
   "source": [
    "# Define the parameter for BayesSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': Integer(50, 500),\n",
    "    'max_features': Categorical(['sqrt', 'log2']),\n",
    "    'max_depth': Integer(10, 50),\n",
    "    'min_samples_split': Integer(2, 50),\n",
    "    'min_samples_leaf': Integer(1, 50)\n",
    "}\n",
    "# Arrays to store execution times, memory usage, CPU usage, and evaluation scores\n",
    "rand_time = np.zeros(5,'float')\n",
    "rand_mem = np.zeros(5,'float')\n",
    "rand_cpu =  np.zeros(5,'float')\n",
    "rand_score = np.zeros(5,'float')\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    bayes_search = BayesSearchCV(estimator=rf, search_spaces=param_dist,\n",
    "                             n_iter=70, cv=3, n_jobs=-1)\n",
    "\n",
    "    # Monitor the current process, record the start time, initial CPU usage, and memory usage in MB\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_time = time.time()\n",
    "    start_cpu = process.cpu_percent(interval=None)\n",
    "    start_mem = process.memory_info().rss / (1024 * 1024) \n",
    "\n",
    "    bayes_search.fit(X_train, y_train)\n",
    "\n",
    "    end_time = time.time()\n",
    "    end_cpu = process.cpu_percent(interval=None)\n",
    "    end_mem = process.memory_info().rss / (1024 * 1024)  \n",
    "\n",
    "    # Calculating execution time, memory usage, and CPU usage\n",
    "    rand_time[i] = end_time - start_time\n",
    "    rand_mem[i] = end_mem - start_mem\n",
    "    rand_cpu[i] = end_cpu - start_cpu\n",
    "\n",
    "    # Training the model with the best parameters and evaluate\n",
    "    rf = RandomForestClassifier(** bayes_search.best_params_ , random_state=42 )\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "    rand_score[i] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# BayesSearchCV results\n",
    "print(f\"Execution Time: mean={np.mean(rand_time):.2f} seconds, std={np.std(rand_time)} seconds, max={np.max(rand_time)} seconds, min={np.min(rand_time)} seconds\")\n",
    "print(f\"CPU Usage: mean={np.mean(rand_cpu):.2f}%, std={np.std(rand_cpu):.2f}%, max={np.max(rand_cpu):.2f}%, min={np.min(rand_cpu):.2f}%\")\n",
    "print(f\"Memory Usage: mean={np.mean(rand_mem):.2f} MB, std={np.std(rand_mem):.2f} MB, max={np.max(rand_mem):.2f} MB, min={np.min(rand_mem):.2f} MB\")\n",
    "print(f\"Validation Score: mean={np.mean(rand_score)} , std={np.std(rand_score)} , max={np.max(rand_score)} , min={np.min(rand_score)} \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
